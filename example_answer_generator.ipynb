{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for the Answer Generator model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports + model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from models.qa import AnswerGenerator\n",
    "from utils import set_display_options\n",
    "from datasets import get_dataset, prepare_dataset, train_test_split, test_dataset_time\n",
    "\n",
    "set_display_options()\n",
    "\n",
    "model_name = 'bart_qa'\n",
    "bert_base  = 'facebook/bart-large'\n",
    "\n",
    "print(\"Tensorflow version : {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lang'             : 'en',\n",
    "    'input_format'     : ['{question}', '{context}'],\n",
    "    'output_format'    : '{answer}',\n",
    "    'text_encoder'     : bert_base,\n",
    "    'max_input_length' : 512,\n",
    "    \n",
    "    'pretrained' : bert_base\n",
    "}\n",
    "\n",
    "model = AnswerGenerator(nom = model_name, ** config)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model instanciation + dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AnswerGenerator(nom = model_name, max_to_keep = 1)\n",
    "\n",
    "lr = {'name' : 'WarmupScheduler', 'maxval' : 5e-5,'minval' : 1e-5, 'factor' : 512, 'warmup_steps' : 8192}\n",
    "lr = 1e-5\n",
    "\n",
    "model.compile(optimizer = 'adam', optimizer_config = {'lr' : lr}, metrics = ['TextAccuracy', 'F1'])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = 'squad' if 'nq' not in model_name else 'nq'\n",
    "\n",
    "dataset = get_dataset(datasets, clean_text = True, skip_impossible = True, keep_mode = 'longest')\n",
    "train, valid = dataset['train'], dataset['valid']\n",
    "\n",
    "\n",
    "print(\"Dataset length :\\n  Training set : {}\\n  Validation set : {}\".format(\n",
    "    len(train), len(valid)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "batch_size = 8 if datasets == 'squad' else 6\n",
    "shuffle_size = batch_size * 32\n",
    "\n",
    "max_input_length = 512\n",
    "max_output_length = 128\n",
    "\n",
    "print(\"Training samples   : {} - {} batches\".format(len(train), len(train) // batch_size))\n",
    "print(\"Validation samples : {} - {} batches\".format(len(valid), len(valid) // (batch_size * 2)))\n",
    "\n",
    "hist = model.train(\n",
    "    train, validation_data = valid, \n",
    "    epochs = epochs, batch_size = batch_size, valid_batch_size = 2.,\n",
    "    shuffle_size = shuffle_size, max_input_length = max_input_length, max_output_length = max_output_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_history()\n",
    "print(model.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = model.get_dataset_config(batch_size = 2, is_validation = False, shuffle_size = 0)\n",
    "ds = prepare_dataset(valid.sample(10, random_state = 0), ** config)\n",
    "\n",
    "for batch in ds.take(5):\n",
    "    model.predict_with_target(batch, n_pred = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = model.get_dataset_config(batch_size = 16, is_validation = False, shuffle_size = 0)\n",
    "ds = prepare_dataset(valid, ** config)\n",
    "\n",
    "test_dataset_time(ds, steps = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_train_objects.optimizers import WarmupScheduler\n",
    "\n",
    "lr = WarmupScheduler(maxval = 1e-3, minval = 1e-4, factor = 256, warmup_steps = 4096)\n",
    "lr.plot(25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = model.get_optimizer().learning_rate\n",
    "lr.assign(5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = model.get_optimizer().learning_rate\n",
    "print(lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
