{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for the Memory Augmented Generator (MAG) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports + model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.6.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from loggers import set_level, add_handler\n",
    "from models.qa import MAG\n",
    "from utils import set_display_options\n",
    "from datasets import get_dataset, prepare_dataset, train_test_split, test_dataset_time\n",
    "from models.model_utils import get_model_history\n",
    "\n",
    "from experiments_mag import config_from_name, training_config_from_name\n",
    "\n",
    "#set_level('time')\n",
    "set_display_options()\n",
    "\n",
    "model_name = 'm5_nq_coqa_newsqa_mag_split_off_entq_ct_wt_ib_2_2_dense'\n",
    "bert_base  = 'facebook/bart-large'\n",
    "\n",
    "print(\"Tensorflow version : {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = config_from_name(model_name)\n",
    "config.pop('class')\n",
    "\n",
    "if 'pretrained_name' in config and not is_model_name(config['pretrained_name'])::\n",
    "    logging.warning('Pretrained model {} does not exists !'.format(config['pretrained_name']))\n",
    "    config.pop('pretrained_name')\n",
    "\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "if 'pretrained_name' in config:\n",
    "    model = MAG.from_pretrained(nom = model_name, pretrained_name = model_name.replace('dense', 'mean'), ** config)\n",
    "else:\n",
    "    model = MAG(nom = model_name, ** config)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model.model.freeze(trainable = True)\n",
    "model.encoder.subsampling_layer.trainable = False\n",
    "model.summary()\n",
    "model.model.encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model instanciation + dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MAG(nom = model_name, max_to_keep = 2)\n",
    "\n",
    "if 'dense' in model_name:\n",
    "    lr = {'name' : 'WarmupScheduler', 'maxval' : 5e-5,'minval' : 1e-5, 'factor' : 512, 'warmup_steps' : 8192}\n",
    "    lr = {'name' : 'DivideByStep', 'maxval' : 1e-5,'minval' : 1e-6, 'factor' : 0.1}\n",
    "else:\n",
    "    lr = 1e-5\n",
    "\n",
    "model.compile(optimizer = 'adam', optimizer_config = {'lr' : lr}, metrics = ['TextAccuracy', 'F1'])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = 'squad' if 'nq' not in model_name else 'nq'\n",
    "#datasets = ['nq', 'squad']\n",
    "\n",
    "use_doc = True if 'nq' in datasets and 'doc' in model_name else False\n",
    "use_doc = True\n",
    "\n",
    "dataset = get_dataset(\n",
    "    datasets, clean_text = True, skip_impossible = True, shuffle = True, use_long_answer = False,\n",
    "    include_document = use_doc, keep_mode = 'all'\n",
    ")\n",
    "train, valid = dataset['train'], dataset['valid']\n",
    "\n",
    "print(\"Dataset length :\\n  Training set : {}\\n  Validation set : {}\".format(\n",
    "    len(train), len(valid)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.array([model.encode_data(row)[1][1] for row in tqdm(train.sample(10000).to_dict('records'))])\n",
    "print(freqs)\n",
    "print(np.sum(freqs <= 64 * 3))\n",
    "plot(freqs, plot_type = 'hist')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = None\n",
    "\n",
    "add_handler('telegram', token = TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fine_tuning = True\n",
    "\n",
    "if fine_tuning and 'dense' not in model_name:\n",
    "    model.get_optimizer().learning_rate.assign(1e-5)\n",
    "\n",
    "#if 'dense' in model_name and model.epochs == 0:\n",
    "#    model.encoder.subsampling_layer.trainable = False\n",
    "\n",
    "epochs = 1 if fine_tuning else 1\n",
    "if not isinstance(epochs, (list, tuple)): epochs = [epochs]\n",
    "\n",
    "if datasets == 'squad':\n",
    "    batch_size = 8 if fine_tuning else 16\n",
    "else:\n",
    "    if model.subsampling_factor < 2:\n",
    "        batch_size = 3 if fine_tuning else 16\n",
    "    elif model.subsampling_factor == 2:\n",
    "        batch_size = 4 if fine_tuning else 16\n",
    "    elif model.subsampling_factor == 3:\n",
    "        batch_size = 5 if fine_tuning else 16\n",
    "    elif model.subsampling_factor == 5:\n",
    "        batch_size = 6 if fine_tuning else 16\n",
    "\n",
    "max_negatives = 5\n",
    "\n",
    "shuffle_size = 0 if sum(epochs) + model.epochs == 1 else batch_size * 32\n",
    "\n",
    "augment_prct = 0. if use_doc else 0.25\n",
    "nb_mask = 1 if 'aug' not in model_name else 2\n",
    "min_mask_length = 1\n",
    "max_mask_length = 1 if 'aug' not in model_name else 2\n",
    "\n",
    "negative_mode = None\n",
    "if 'ib' in model_name:\n",
    "    negative_mode = 'batch'\n",
    "elif use_doc:\n",
    "    negative_mode = 'doc'\n",
    "\n",
    "max_input_length = 512\n",
    "max_output_length = 128\n",
    "\n",
    "if use_doc: batch_size = batch_size // 2\n",
    "elif 'split' in model_name : batch_size -= 1\n",
    "\n",
    "print(\"Training samples   : {} - {} batches\".format(len(train), len(train) // batch_size))\n",
    "print(\"Validation samples : {} - {} batches\".format(len(valid), len(valid) // (batch_size * 2)))\n",
    "\n",
    "for e in epochs:\n",
    "    hist = model.train(\n",
    "        train, validation_data = valid, \n",
    "        epochs = e, batch_size = batch_size, valid_batch_size = 2.,\n",
    "        shuffle_size = shuffle_size, max_input_length = max_input_length, max_output_length = max_output_length,\n",
    "        negative_mode = negative_mode, max_negatives = max_negatives, \n",
    "        is_rectangular = False if use_doc else True,\n",
    "\n",
    "        augment_prct = augment_prct, nb_mask = nb_mask, min_mask_length = min_mask_length, max_mask_length = max_mask_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_history()\n",
    "print(model.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.history.trainings_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model_utils import get_model_history\n",
    "from utils import time_to_string\n",
    "\n",
    "h = get_model_history('m_nq_mag_off_3_12_mean')\n",
    "pd.DataFrame(h.logs)\n",
    "time_to_string(13000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(valid, batch_size = 8)\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(\n",
    "    valid, batch_size = 12, max_input_length = 512, negative_mode = None, is_rectangular = True,\n",
    "    max_negatives = 5, max_output_length = 32, add_loss = False, metrics = ['F1'],\n",
    "    teacher_forcing_eval = False, eval_infer_config = {}, verbose = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_level('info')\n",
    "\n",
    "config = model.get_dataset_config(batch_size = 5, is_validation = True, shuffle_size = 0)\n",
    "ds = prepare_dataset(valid.sample(25, random_state = 0), ** config, is_rectangular = not use_doc)\n",
    "\n",
    "for batch in ds:\n",
    "    model.predict_with_target(batch, n_pred = 10, debug = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "question = [\n",
    "    'How is the night vision of cat ?',\n",
    "    'How is the night vision of cat ?',\n",
    "    'What is the anoatomy of a cat ?',\n",
    "    'How many paws does a cat have ?',\n",
    "    'How many paws does a cat have ?',\n",
    "    'How many paws does a cat have ?',\n",
    "    'What is the origin of life ?'\n",
    "]\n",
    "context  = [\n",
    "    'The cat is similar in anatomy to the other felid species: it has a strong flexible body, \\\n",
    "quick reflexes, sharp teeth and retractable claws adapted to killing small prey. Its night vision and sense of smell are well \\\n",
    "developed. Cat communication includes vocalizations like meowing, purring, trilling, hissing, growling and grunting as well as cat-\\\n",
    "specific body language. A predator that is most active at dawn and dusk (crepuscular), the cat is a solitary hunter but a social species. \\\n",
    "It can hear sounds too faint or too high in frequency for human ears, such as those made by mice and other small mammals.[7] It secretes and \\\n",
    "perceives pheromones.',\n",
    "    [p.strip() + '.' for p in 'The cat is similar in anatomy to the other felid species: it has a strong flexible body, \\\n",
    "quick reflexes, sharp teeth and retractable claws adapted to killing small prey. Its night vision and sense of smell are well \\\n",
    "developed. Cat communication includes vocalizations like meowing, purring, trilling, hissing, growling and grunting as well as cat-\\\n",
    "specific body language. A predator that is most active at dawn and dusk (crepuscular), the cat is a solitary hunter but a social species. \\\n",
    "It can hear sounds too faint or too high in frequency for human ears, such as those made by mice and other small mammals.[7] It secretes and \\\n",
    "perceives pheromones.'.split('.') if len(p) > 0],\n",
    "    ['The cat is similar in anatomy to the other felid species: it has a strong flexible body, \\\n",
    "quick reflexes, sharp teeth and retractable claws adapted to killing small prey. Its night vision and sense of smell are well \\\n",
    "developed. Cat communication includes vocalizations like meowing, purring, trilling, hissing, growling and grunting as well as cat-\\\n",
    "specific body language. A predator that is most active at dawn and dusk (crepuscular), the cat is a solitary hunter but a social species. \\\n",
    "It can hear sounds too faint or too high in frequency for human ears, such as those made by mice and other small mammals.[7] It secretes and \\\n",
    "perceives pheromones.', 'The answer to everything is 42'],\n",
    "    'A cat is an animal which has 4 paws and whiskers.',\n",
    "    'A cat is an animal which has 4 paws and whiskers. However, everyone knows that the answer to everything is 42 !',\n",
    "    ['A cat is an animal which has 4 paws and whiskers.', 'However, everyone knows that the answer to everything is 42 !'],\n",
    "    'The answer to everything is 42.'\n",
    "]\n",
    "\n",
    "n = 1\n",
    "#question, context = question[n], [context[n]]\n",
    "\n",
    "if not isinstance(question, list): question = [question]\n",
    "if not isinstance(context, list): context = [context]\n",
    "\n",
    "answers = model.predict(question, context, title = 'cat', method = 'beam')\n",
    "\n",
    "for q, c, a in zip(question, context, answers):\n",
    "    print(\"Question : {}\\nContext : {}\\nAnswer : {}\\n\".format(q, c, model.infer_to_str(a[0], a[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q, c, a in zip(question, context, answers):\n",
    "    print(\"Question : {}\\nContext : {}\\nAnswer : {}\\n\".format(q, c, a))\n",
    "    print(model.infer_to_str(a[1], a[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from utils import plot_multiple\n",
    "from models.model_utils import compare_models, get_models, remove_training_checkpoint\n",
    "\n",
    "def _extract_topk_tests(infos, color_corr):\n",
    "    top5_prefix = set([c.split('-')[0] for c in infos.columns if 'top5' in c and 'test' in c])\n",
    "    to_drop     = [c for c in infos.columns if 'top5' in c]\n",
    "    \n",
    "    top5_results = {}\n",
    "    for prefix in top5_prefix:\n",
    "        top5_results[prefix] = {'x' : {}, 'with_legend' : False}\n",
    "        for _, row in infos.iterrows():\n",
    "            if row['nom'].startswith('m4_') and 'squad' not in prefix: continue\n",
    "            \n",
    "            k = np.array(sorted([int(c.split('-')[-1]) for c in infos.columns if c.startswith(prefix)]))\n",
    "            score = {c.split('-')[1] : row[c] for c in infos.columns if c.startswith(prefix)}\n",
    "            top5_results[prefix]['x'][row['nom']] = {\n",
    "                'x' : k,\n",
    "                'y' : np.array([score[str(k)] for k in k]),\n",
    "                'c' : _colors[row[color_corr]],\n",
    "                'ls': _styles[row['nom'][:2]] if 'split' not in row['nom'] else '-.'\n",
    "            }\n",
    "    return infos.drop(to_drop, axis = 1), top5_results\n",
    "\n",
    "def plot_and_sort(infos, metric = 'val_loss', color_corr = 'encoder_subsampling_step', shape_corr = None, ascending = True):\n",
    "    to_drop = [c for c in _cols_to_drop if c in infos.columns]\n",
    "    to_drop += [c for c in infos.columns if 'test_doc' in c and '-' not in c]\n",
    "    infos = infos.drop(to_drop, axis = 1)\n",
    "    if 'negative_mode' in infos.columns:\n",
    "        infos['negative_mode'].fillna('none', inplace = True)\n",
    "        infos.loc[infos['negative_mode'] != 'doc', 'max_negatives'] = -1\n",
    "        \n",
    "    if 'split_contexts' in infos.columns:\n",
    "        infos['split_contexts'].fillna(False, inplace = True)\n",
    "        infos.loc[infos['split_contexts'] != False, 'max_sent_per_ctx'] = -1\n",
    "\n",
    "    if 'encoder_subsampling_mode' in infos.columns:\n",
    "        infos['encoder_subsampling_mode'].fillna('none', inplace = True)\n",
    "        if 'encoder_subsampling_step' in infos.columns:\n",
    "            infos['encoder_subsampling_step'].fillna(0, inplace = True)\n",
    "            infos.loc[infos['encoder_subsampling_step'] < 2, 'encoder_subsampling_mode'] = 'none'\n",
    "\n",
    "    infos['nom'] = infos.index\n",
    "    infos, top_k_tests = _extract_topk_tests(infos, color_corr)\n",
    "            \n",
    "    plot_multiple(\n",
    "        infos, corr = metric, ** top_k_tests, linewidth = 5,\n",
    "        color_corr = color_corr if color_corr in infos.columns else None, color_order = _colors,\n",
    "        shape_corr = shape_corr if shape_corr in infos.columns else None, shape_order = _shapes,\n",
    "        link_from_to = ('pretrained_name', 'nom'),\n",
    "        ncols = 4, x_size = 4, y_size = 4#, filename = 'mag_plots/{}.png'.format(metric), show = True\n",
    "    )\n",
    "\n",
    "    return infos.sort_values(metric, ascending = ascending)\n",
    "\n",
    "_colors = {\n",
    "    i : color for i, color in enumerate(['w', 'r', 'cyan', 'g', 'b', 'violet'])\n",
    "}\n",
    "_shapes = {\n",
    "    mode : shape for mode, shape in [('none', 'o'), ('mean', 'x'), ('dense', 'D')]\n",
    "}\n",
    "_styles = {\n",
    "    'm3' : 'dotted',\n",
    "    'm4' : 'solid',\n",
    "    'm5' : '--'\n",
    "}\n",
    "_cols_to_drop = [\n",
    "    'input_format', 'shuffle_size', 'eval_infer_config', 'augment_prct', 'max_output_length'\n",
    "]\n",
    "\n",
    "names = get_models('m3_nq_mag_off_entq_ct_wt_*') + ['m3_nq']\n",
    "names += get_models('m5_*') + get_models('m4_*')\n",
    "\n",
    "# names += [n for n in os.listdir('pretrained_models') if n.startswith('test_mag_')]\n",
    "\n",
    "infos = compare_models(names, True, True, epoch = 'last', add_training_config = True)\n",
    "\n",
    "plot_and_sort(\n",
    "    infos, 'val_loss',\n",
    "    color_corr = 'encoder_subsampling_step' if 'encoder_subsampling_step' in infos.columns else 'negative_mode',\n",
    "    shape_corr = 'encoder_subsampling_mode'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_sort(\n",
    "    infos, 'test_F1',\n",
    "    color_corr = 'encoder_subsampling_step' if 'encoder_subsampling_step' in infos.columns else 'negative_mode',\n",
    "    shape_corr = 'encoder_subsampling_mode',\n",
    "    ascending  = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_sort(\n",
    "    infos, 'test_squad_F1',\n",
    "    color_corr = 'encoder_subsampling_step' if 'encoder_subsampling_step' in infos.columns else 'negative_mode',\n",
    "    shape_corr = 'encoder_subsampling_mode',\n",
    "    ascending  = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from utils import load_json, dump_json\n",
    "from models.model_utils import get_models\n",
    "\n",
    "names = get_models('m3_nq_mag*')\n",
    "\n",
    "for name in names:\n",
    "    filename = os.path.join('pretrained_models', name, 'config.json')\n",
    "    \n",
    "    config = load_json(filename)\n",
    "    \n",
    "    config['config'].update({\n",
    "        'context_offset' : -1,\n",
    "        'encoder_positional_offset' : 128\n",
    "    })\n",
    "    \n",
    "    dump_json(filename, config, indent = 4)\n",
    "    \n",
    "    filename = os.path.join('pretrained_models', name, 'saving', 'model.json')\n",
    "    \n",
    "    config = load_json(filename)\n",
    "    \n",
    "    config['config'].update({\n",
    "        'encoder_positional_offset' : 128\n",
    "    })\n",
    "    \n",
    "    dump_json(filename, config, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from models.model_utils import get_models, remove_training_checkpoint\n",
    "\n",
    "for n in get_models('m4*'):\n",
    "    remove_training_checkpoint(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.negative_mode = 'doc'\n",
    "model.max_negatives = 5\n",
    "model.max_input_length = 512\n",
    "model.max_sentence_length = 128\n",
    "\n",
    "config = model.get_dataset_config(batch_size = 16, is_validation = False, shuffle_size = 0)\n",
    "ds = prepare_dataset(valid, ** config, is_rectangular = False)\n",
    "\n",
    "test_dataset_time(ds, steps = 1000 if not use_doc else 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import models.qa.mag as mag\n",
    "import models.qa.answer_generator_split as answer_generator_split\n",
    "\n",
    "importlib.reload(answer_generator_split)\n",
    "importlib.reload(mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds(model):\n",
    "    model.negative_mode = 'doc'\n",
    "    model.max_negatives = 8\n",
    "    model.max_input_length = 512\n",
    "    model.max_sentence_length = 128\n",
    "    model.max_sent_per_ctx    = 5\n",
    "\n",
    "    config = model.get_dataset_config(batch_size = 1, is_validation = True, prefetch = False, prefetch_size = 0)\n",
    "    ds = prepare_dataset(valid, ** config, is_rectangular = False)\n",
    "    return ds\n",
    "\n",
    "ds = get_ds(model)\n",
    "\n",
    "for (inp, out) in ds.take(20):\n",
    "    print(\"Inputs shape : {}\".format([tuple(i.shape) for i in inp[:-2]]))\n",
    "    print(\"Total length : {}\\n\".format(inp[1] + tf.reduce_sum(inp[3], axis = -1)))\n",
    "    #print(\"Outputs shape : {}\".format([tuple(i.shape) for i in out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_train_objects.optimizers import WarmupScheduler, DivideByStep\n",
    "\n",
    "lr = WarmupScheduler(maxval = 5e-5, minval = 5e-6, factor = 32, warmup_steps = 128)\n",
    "lr = DivideByStep(0.5, maxval = 5e-5, minval = 5e-6)\n",
    "lr.plot(50000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
